{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The APF wavelength solution we have been using is not quite accurate. \n",
    "# Howard has provided another one (which is still not perefeclty accurate but much better - see explore_wl_soln.ipynb). \n",
    "\n",
    "# We could fix this by re-running everything with the new wavelength solution. But, since SM-Emp first shifts the spectrum into the stellar\n",
    "# rest frame before matching, the shifted spectrum and residual should be on correct scales. So, we only need to fix the wavelength scale \n",
    "# for the unshifted spectrum, then redefine the velocity shift values.\n",
    "\n",
    "# In fact, this should only need to be done once: the unshifted spectra are all on the same wavelength scale. No that's wrong. \n",
    "# We need to do this for each target, because the spectrum itself will be different (essentially the start and endpoints that are mapped\n",
    "# to the start and end of the reference wl scale will be different). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from bstar_deblaze.ipynb\n",
      "importing Jupyter notebook from rescale.ipynb\n",
      "Finished rescale\n",
      "Reading library from /home/azuckerman/.specmatchemp/library.h5\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from bstar_deblaze import bstar_deblazed2 #ADZ ADD 7/17/20\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import astropy.io.fits as fits\n",
    "from rescale import get_rescaled_wave_soln\n",
    "#from rescale import resample_order\n",
    "import sys\n",
    "import os\n",
    "# Specmatch imports (relative to current directory)\n",
    "sys.path.insert(0, '/mnt_home/azuckerman/BL_APF_DAP/specmatch_emp')\n",
    "from specmatch_emp.specmatchemp import library\n",
    "from specmatch_emp.specmatchemp import plots as smplot\n",
    "from specmatch_emp.specmatchemp.spectrum import Spectrum\n",
    "from specmatch_emp.specmatchemp.specmatch import SpecMatch\n",
    "new_apf_wave_soln = (fits.open('apf_wave_2022.fits'))[0].data\n",
    "\n",
    "# define new resampling function (resample each order individually, and then combine)\n",
    "def new_resample(wave_soln_ref, wave_soln, spectrum):\n",
    "    resampled_orders = np.empty(shape=(0)) \n",
    "    resampled_wl = np.empty(shape=(0)) # contains resampled wl for each order concatenated (so there are repeats)\n",
    "    for order in np.arange(30,52,1):\n",
    "        order_values = spectrum[order][100:-100] # truncate the ends becuase the deblazing doesn't work well here --> unless in future iteration do this in deblazing\n",
    "        apf_wl_values = wave_soln[order][100:-100]\n",
    "        first = apf_wl_values[0]\n",
    "        last = apf_wl_values[-1]\n",
    "        new_first = first - 0.017 \n",
    "        new_last = last + 0.17 \n",
    "        new_wl_section = np.array(wave_soln_ref)[(new_first <= wave_soln_ref) * (new_last >= wave_soln_ref)]\n",
    "        resampled_order = resample_order(new_wl_section, apf_wl_values, order_values)\n",
    "        resampled_orders = np.hstack([resampled_orders, resampled_order])\n",
    "        resampled_wl = np.hstack([resampled_wl, new_wl_section])\n",
    "    # average duplicate flux values\n",
    "    resampled_spectrum = np.zeros(len(wave_soln_ref))\n",
    "    i=0\n",
    "    for wl in wave_soln_ref:\n",
    "        values = resampled_orders[resampled_wl == wl]\n",
    "        avg = np.nanmean(values)\n",
    "        resampled_spectrum[i] = avg\n",
    "        i += 1       \n",
    "    return resampled_spectrum\n",
    "\n",
    "# define new resampling function for baseline photons -> sum not average in overlap regions\n",
    "def new_resample_baseline(wave_soln_ref, wave_soln, arr):\n",
    "    resampled_orders = np.empty(shape=(0)) \n",
    "    resampled_wl = np.empty(shape=(0)) # contains resampled wl for each order concatenated (so there are repeats)\n",
    "    for order in np.arange(30,52,1):\n",
    "        #order_values = arr[order][100:-101] # truncate the ends becuase the deblazing doesn't work well here --> unless in future iteration do this in deblazing\n",
    "        #apf_wl_values = wave_soln[order][100:-100]\n",
    "        order_values = arr[order][:-1] \n",
    "        apf_wl_values = wave_soln[order][:-1]\n",
    "        first = apf_wl_values[0]\n",
    "        last = apf_wl_values[-1]\n",
    "        new_first = first - 0.017 \n",
    "        new_last = last + 0.17 \n",
    "        new_wl_section = np.array(wave_soln_ref)[(new_first <= wave_soln_ref) * (new_last >= wave_soln_ref)]\n",
    "        resampled_order = resample_order(new_wl_section, apf_wl_values, order_values)\n",
    "        resampled_orders = np.hstack([resampled_orders, resampled_order])\n",
    "        resampled_wl = np.hstack([resampled_wl, new_wl_section])\n",
    "    # sum duplicate flux values\n",
    "    resampled_arr = np.zeros(len(wave_soln_ref))\n",
    "    i=0\n",
    "    for wl in wave_soln_ref:\n",
    "        values = resampled_orders[resampled_wl == wl]\n",
    "        total = np.nansum(values)\n",
    "        resampled_arr[i] = total\n",
    "        i += 1       \n",
    "    return resampled_arr\n",
    "\n",
    "def resample_order(wave_data_new, wave_data_old, data):\n",
    "    # MODIFED VERSION!!\n",
    "    import numpy as np\n",
    "\n",
    "    w_lst = wave_data_old\n",
    "    s_lst = data\n",
    "\n",
    "    # create array that has wavelengths in column 0 and intensity in column 1\n",
    "    ws = np.zeros((len(w_lst), 2))\n",
    "    for i in range(len(w_lst)):\n",
    "        ws[i,0] = w_lst[i]\n",
    "        ws[i,1] = s_lst[i]\n",
    "\n",
    "    # sort the array by increasing wavelength\n",
    "    # the result of merging spectral orders does not strictly increase\n",
    "    # because orders overlap in wavelength ranges\n",
    "    # ws = ws[ws[:, 0].argsort()]\n",
    "\n",
    "    # select to skip first 137 values (closer to 4997 Å) - via eye test\n",
    "    # ws = ws[137:]\n",
    "    \n",
    "    # average intensity values within +/- 0.017 Å on the new wavelength scale\n",
    "    \n",
    "    # comparisons between wavelengths in the old and new scale start from the\n",
    "    # beginning of the old wavelength array for each new wavelength value\n",
    "    # inefficient, so data points in the front of the array are clipped every\n",
    "    # 1000 comparisons to reduce time wasted on wavelength comparisons\n",
    "    data_new = []\n",
    "    count = 0\n",
    "    pairs = ws.tolist() # pairs -> (old wavelength, old intensity)\n",
    "    for w in wave_data_new: # for every new wavelength value\n",
    "        if (count != 0):\n",
    "            if ((count % 1000 == 0)): # for every thousand comparisons\n",
    "\n",
    "                # remove 800 pairs from the beginning of the\n",
    "                # list of old values\n",
    "                removed_1 = pairs[:800]\n",
    "                removed_1.reverse()\n",
    "                del pairs[:800]\n",
    "\n",
    "                # if we remove too many,\n",
    "                # the new wavelength value is less than the\n",
    "                # starting wavelength value in the old list\n",
    "                # i.e. (w_new - w_old < 0)\n",
    "                # so we return some of the pairs\n",
    "                if (w - pairs[0][0] < 0):\n",
    "                    for pair in removed_1:\n",
    "                        pairs.insert(0, pair)\n",
    "                        break # currently breaks after inserting one pair\n",
    "\n",
    "                # while the new wavelength value is greater than\n",
    "                # the starting wavelength in the old list by more than a tenth,\n",
    "                # remove a pair\n",
    "                # (to improve efficiency, avoiding unneccessary comparisons)\n",
    "                while ((w - pairs[0][0] > .1)):\n",
    "                    removed_2 = pairs[0]\n",
    "                    del pairs[0]\n",
    "                    if (w - pairs[0][0] < 0): # replace if (w_new - w_old < 0)\n",
    "                        pairs.insert(0, removed_2)\n",
    "                        break\n",
    "        avg_lst = []\n",
    "        some_found = False\n",
    "        for pair in pairs:\n",
    "            # comparison process between new and old wavelength values\n",
    "            if (abs(w - pair[0]) < .017):\n",
    "                avg_lst.append(pair[1])\n",
    "                some_found = True\n",
    "            elif (some_found): break # break when the inequality no longer holds\n",
    "        data_new.append(np.mean(np.asarray(avg_lst)))\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "    #print('Finished resample') #ADZ DELETE THIS 6/23/20\n",
    "    return data_new\n",
    "\n",
    "# Get a wavelength solution rescaled onto the scale of the library\n",
    "wave_soln_ref = get_rescaled_wave_soln()\n",
    "\n",
    "# library\n",
    "lib = library.read_hdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD210610_spectra_2\n",
      "HD210610_spectra_3\n",
      "HD210610_spectra_4\n",
      "HD210610_spectra_5\n",
      "HIP5336_spectra_0\n",
      "HIP5336_spectra_1\n",
      "HIP5336_spectra_2\n",
      "HIP5336_spectra_3\n",
      "HIP5336_spectra_4\n",
      "HIP5336_spectra_5\n",
      "HIP5336_spectra_6\n",
      "HIP6379_spectra_0\n",
      "HIP6379_spectra_1\n",
      "HIP6379_spectra_2\n",
      "HIP6379_spectra_3\n",
      "HIP6379_spectra_4\n",
      "HIP6379_spectra_5\n",
      "HIP6379_spectra_6\n",
      "HIP7078_spectra_0\n",
      "HIP7078_spectra_1\n",
      "HIP7078_spectra_2\n",
      "HIP7078_spectra_3\n",
      "HIP7078_spectra_4\n",
      "HIP7078_spectra_5\n",
      "HIP7078_spectra_6\n",
      "HIP7513_spectra_0\n",
      "HIP7513_spectra_1\n",
      "HIP7513_spectra_2\n",
      "HIP7513_spectra_3\n",
      "HIP7576_spectra_0\n",
      "HIP7576_spectra_1\n",
      "HIP7576_spectra_2\n",
      "HIP7576_spectra_3\n",
      "HIP7576_spectra_4\n",
      "HIP7576_spectra_5\n",
      "HIP7576_spectra_6\n",
      "HIP7576_spectra_8\n",
      "HIP7734_spectra_0\n",
      "HIP7734_spectra_1\n",
      "HIP7734_spectra_2\n",
      "HIP7734_spectra_3\n",
      "HIP7734_spectra_4\n",
      "HIP7734_spectra_5\n",
      "HIP7981_spectra_0\n",
      "HIP7981_spectra_1\n",
      "HIP7981_spectra_2\n",
      "HIP7981_spectra_3\n",
      "HIP8543_spectra_0\n",
      "HIP8543_spectra_1\n",
      "HIP8543_spectra_2\n",
      "HIP8543_spectra_3\n",
      "HIP8903_spectra_0\n",
      "HIP8903_spectra_1\n",
      "HIP8903_spectra_2\n",
      "HIP8903_spectra_3\n",
      "HIP8903_spectra_4\n",
      "HIP8903_spectra_5\n",
      "HIP8903_spectra_6\n",
      "HIP8903_spectra_7\n",
      "HIP9269_spectra_0\n",
      "HIP9269_spectra_1\n",
      "HIP9269_spectra_2\n",
      "HIP9269_spectra_3\n",
      "HIP9269_spectra_4\n",
      "HIP9269_spectra_5\n",
      "HIP9487_spectra_0\n",
      "HIP9487_spectra_1\n",
      "HIP9487_spectra_2\n",
      "HIP9487_spectra_3\n",
      "HIP9487_spectra_4\n",
      "HIP9487_spectra_5\n",
      "HIP9487_spectra_6\n",
      "HIP9487_spectra_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bstar_deblaze.ipynb:269: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"    #scale_factors /= np.percentile(np.sort(y),99)\\n\",\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIP9716_spectra_0\n",
      "HIP9716_spectra_1\n",
      "HIP9716_spectra_2\n",
      "HIP9716_spectra_3\n",
      "HIP9716_spectra_4\n",
      "HIP9716_spectra_5\n",
      "HIP9716_spectra_6\n",
      "HIP9884_spectra_0\n",
      "HIP9884_spectra_1\n",
      "HIP9884_spectra_2\n",
      "HIP9884_spectra_3\n",
      "HIP10644_spectra_0\n",
      "HIP10644_spectra_1\n",
      "HIP10644_spectra_2\n",
      "HIP10644_spectra_3\n",
      "HIP11090_spectra_0\n",
      "HIP11090_spectra_1\n",
      "HIP11090_spectra_2\n",
      "HIP11090_spectra_3\n",
      "HIP11090_spectra_4\n",
      "HIP11090_spectra_5\n",
      "HIP11759_spectra_0\n",
      "HIP11759_spectra_1\n",
      "HIP11759_spectra_2\n",
      "HIP11759_spectra_3\n",
      "HIP12097_spectra_0\n",
      "HIP12097_spectra_1\n",
      "HIP12097_spectra_2\n",
      "HIP12097_spectra_3\n",
      "HIP12097_spectra_4\n",
      "HIP12097_spectra_5\n",
      "HIP12390_spectra_0\n",
      "HIP12390_spectra_1\n",
      "HIP12390_spectra_2\n",
      "HIP12390_spectra_3\n",
      "HIP12390_spectra_4\n",
      "HIP12390_spectra_5\n"
     ]
    }
   ],
   "source": [
    "#  Get spectra filelist\n",
    "path_to_dir = './APF_spectra/all_individual_spectra_clean' # change for each run\n",
    "run_type = 'ind' # all_apf, all_obs, or ind\n",
    "filelist = os.listdir(path_to_dir)\n",
    "# for running on a subset of the files\n",
    "\n",
    "try:\n",
    "    filelist.remove('.ipynb_checkpoints') # remove hidden file in this directory\n",
    "    filelist.remove('HIP5643_spectra') # remove problematic spectrum; produces an error but not due to labeling (GJ54.1)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "photon_counts_path =  'SM_photon_counts/' + run_type # first rename SM_photon_counts to SM_photon_coutns_old_wl_scale \n",
    "unshifted_out_path =  'APF_spectra/NDRU_' + run_type # first rename APF_spectra/NDRU_[run_type] to  APF_spectra/NDRU_[run_type]_old_wl_scale\n",
    "\n",
    "\n",
    "for dirname in filelist[2:]:\n",
    "    \n",
    "    print(dirname)\n",
    "    \n",
    "    \n",
    "    sim_name = dirname.split('_')[0] #filename.replace('_spectra', '') # read simbad resolvable name from directory name\n",
    "    # define name for saving shifted spectrum, residual, plots, etc to distinguish files in the case that there are multiple\n",
    "    # subdirectories for the same star in this directory (NOTE: in that case must follow naming structure star_spectra_number\n",
    "    # for each subdirectory)\n",
    "    if dirname.endswith('spectra'):\n",
    "        id_name = sim_name\n",
    "    elif dirname[-1].isdigit():\n",
    "        id_name = sim_name + '_' + dirname.split('_')[-1]\n",
    "    if len(os.listdir(path_to_dir + '/' + dirname)) < 1:\n",
    "        print('Skipping ' + dirname + ' due to empty directory.')\n",
    "        empty_dirs += [dirname]\n",
    "        continue    \n",
    "\n",
    "    path_name = str(path_to_dir) + '/' + dirname       \n",
    "    filenames = [f for f in os.listdir(path_name) if os.path.isfile(os.path.join(path_name, f))] \n",
    "\n",
    "    \n",
    "    # Sum all of the data files for a star\n",
    "    data = np.zeros((79, 4608))\n",
    "    counter = 0\n",
    "    for filename in filenames:\n",
    "        file = fits.open(path_name + '/' + filename)\n",
    "        data_part = file[0].data\n",
    "        if (str(np.shape(data_part)) != '(79, 4608)'):\n",
    "            print(str(np.shape(data_part)) + ' is an incompatible data shape.')\n",
    "            print('Cannot perform shift-and-match process.')\n",
    "            sys.exit()\n",
    "        if counter == 0: #ADZ 7/26/20: get the header from the first file for this star, to use for the residual fits file \n",
    "            use_header = file[0].header\n",
    "        counter += 1\n",
    "        try:\n",
    "            data += data_part\n",
    "        except ValueError:\n",
    "            ve = True\n",
    "            \n",
    "    data_deblaze = np.copy(data)\n",
    "    data_no_deblaze = np.copy(data)\n",
    "    for order_inc in range(22):\n",
    "        data_deblaze[30 + order_inc, :4600], ignore1, ignore2, ingore3 = bstar_deblazed2(data, 30 + order_inc)  \n",
    "        \n",
    "\n",
    "    # Resample the spectrum onto the new wavelength scale\n",
    "    new_data_resamp = new_resample(wave_soln_ref, new_apf_wave_soln, data_deblaze)\n",
    "    \n",
    "    # resample the raw photon values without deblazing\n",
    "    resamp_no_deblaze = new_resample_baseline(wave_soln_ref, new_apf_wave_soln, data_no_deblaze)\n",
    "    \n",
    "    # save array of absolute fluxes values\n",
    "    save_photon_counts = True\n",
    "    if save_photon_counts:\n",
    "        photons_file = photon_counts_path + '/photon_counts_' + id_name + '.csv'\n",
    "        photons_df = pd.DataFrame(resamp_no_deblaze)\n",
    "        photons_df.to_csv(photons_file, index = False)\n",
    "\n",
    "    # Create spectrum object\n",
    "    my_spectrum = Spectrum(np.asarray(wave_soln_ref), np.asarray(new_data_resamp))\n",
    "    my_spectrum.name = sim_name\n",
    "\n",
    "    #lib = specmatchemp.library.read_hdf() ADZ 8/10/20 moved this to outer loop so can remove stars from library\n",
    "    \n",
    "    sm = SpecMatch(my_spectrum, lib)\n",
    "    \n",
    "    # save the unshifted spectrum to a fits file\n",
    "    save_unshifted = True\n",
    "    if save_unshifted:\n",
    "        target = sm.target.s\n",
    "        target_wl = sm.target.w   \n",
    "        new_header = use_header\n",
    "        new_header.set('NRDU', 'YES','Normalized, resampled, deblazed, unshifted')\n",
    "        data_hdu = fits.PrimaryHDU(target, new_header) \n",
    "        wl_hdu = fits.ImageHDU(target_wl)\n",
    "        hdu = fits.HDUList([data_hdu, wl_hdu])\n",
    "        hdu.writeto(unshifted_out_path + '/' +  id_name + '_NDRU.fits')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
